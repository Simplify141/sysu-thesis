%%
% 摘要信息
% 本文档中前缀"c-"代表中文版字段, 前缀"e-"代表英文版字段
% 摘要内容应概括地反映出本论文的主要内容，主要说明本论文的研究目的、内容、方法、成果和结论。要突出本论文的创造性成果或新见解，不要与引言相 混淆。语言力求精练、准确，以 300—500 字为宜。
% 在摘要的下方另起一行，注明本文的关键词（3—5 个）。关键词是供检索用的主题词条，应采用能覆盖论文主要内容的通用技术词条(参照相应的技术术语 标准)。按词条的外延层次排列（外延大的排在前面）。摘要与关键词应在同一页。
% modifier: 黄俊杰(huangjj27, 349373001dc@gmail.com)
% update date: 2017-04-15
%%

\cabstract{
    量化交易过程需要交易因子作为指示信号从而为交易决策提供依据。在现代高频交易场景下，交易因子大多表现为多分支机器学习模型的形式。
    高频量化交易对于低延时有严苛的要求，极低的延时是正确执行交易策略的基本条件。
    而在高频交易的关键路径中，因子模型的推理是交易延时的主要来源，因此提高因子模型推理效率成为降低延时的重要优化手段。
    然而当前广泛使用的开源模型推理框架多针对高并发场景下的推理服务进行优化，缺少针对高频交易中苛刻的低延时场景设计的优化方法。
    为此，本文提出了一种新的多分支因子模型推理框架，通过模型推理流程解耦合设计、系统友好与硬件友好的优化方法和分支推理优化算法，显著提升了多分支因子模型的推理效率。

    本文的工作具体包含推理框架的架构设计、系统友好的内存管理、硬件友好的系统配置与算子配置和分支推理优化算法四个方面。
    整体而言，我们将模型的推理过程划分为预处理和部署两个部分，其中可以通过动态配置指示框架为预处理和部署提供针对性的优化；
    其次，在预处理过程中，我们通过内存池，内存映射和内存锁定等方法预分配内存，减少运行过程中访存中断导致的延时；
    在预处理过程中，框架实现了硬件友好的算子动态绑定，在运行过程中则可执行相关系统配置命令，提高算子的执行速度；
    最后，本文引入了基于分支结构的缓存机制，通过动态配置缓存策略，有效提高推理效率。
    实验结果表明，该框架在高频交易场景下的相较开源推理框架具有优越的性能，为交易系统中的多分支因子模型推理提供了新的工具。

    %摘要应概括论文的主要信息，应具有独立性和自含性，即不阅读论文的全文，就能获得必要的信息。摘要内容一般应包括研究目的、内容、方法、成果和结论，要突出论文的创造性成果或新见解，不要与绪论相混淆。语言力求精练、准确，以300-500字为宜。
    %关键词是供检索用的主题词条，应体现论文特色，具有语义性，在论文中有明确的出处，并应尽量采用《汉语主题词表》或各专业主题词表提供的规范词。关键词与摘要应在同一页，在摘要的下方另起一行注明，一般列3-5个，按词条的外延层次排列（外延大的排在前面）。

}
% 中文关键词(每个关键词之间用“，”分开,最后一个关键词不打标点符号。)
\ckeywords{机器学习，高性能计算，低延时交易系统}

\eabstract{
    % 英文摘要及关键词内容应与中文摘要及关键词内容相同。中英文摘要及其关键词各置一页内。
    Quantitative trading relies on trading factors as indicative signals to guide decision-making. In modern high-frequency trading (HFT) scenarios, these factors are predominantly implemented as multi-branch machine learning models. Ultra-low latency is critical in HFT, as it forms the foundation for correctly executing trading strategies. Within the critical path of HFT, the inference latency of factor models constitutes a major contributor to overall trading delays, making the optimization of factor model inference efficiency a pivotal approach to reducing system latency. However, existing open-source model inference frameworks are primarily optimized for high-concurrency inference services and lack dedicated optimizations tailored to the stringent low-latency requirements of HFT.

To address this challenge, this paper proposes a novel multi-branch factor model inference framework. Through decoupled design of model inference processes, system- and hardware-friendly optimization strategies, and branch-aware inference acceleration algorithms, the framework significantly improves the inference efficiency of multi-branch factor models.

The contributions of this work encompass four key aspects:

Architecture Design: The inference pipeline is divided into pre-processing and deployment phases, with dynamic configuration directives enabling phase-specific optimizations.

System-Friendly Memory Management: Pre-allocation techniques including memory pools, memory mapping, and memory locking are implemented to minimize runtime memory access interruptions.

Hardware-Aware Optimization: Hardware-friendly operator binding during pre-processing and runtime system reconfiguration commands enhance computational efficiency.

Branch-Optimized Caching: A cache mechanism based on branch structures dynamically adjusts caching policies to accelerate inference.

Experimental results demonstrate that the proposed framework outperforms existing open-source inference frameworks in HFT scenarios, providing an effective tool for multi-branch factor model inference in trading systems.
}
% 英文文关键词(每个关键词之间用,分开, 最后一个关键词不打标点符号。)
\ekeywords{Machine Learning, High-Performance Computing, Low-Latency Trading System}
