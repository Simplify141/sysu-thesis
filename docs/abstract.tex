%%
% 摘要信息
% 本文档中前缀"c-"代表中文版字段, 前缀"e-"代表英文版字段
% 摘要内容应概括地反映出本论文的主要内容，主要说明本论文的研究目的、内容、方法、成果和结论。要突出本论文的创造性成果或新见解，不要与引言相 混淆。语言力求精练、准确，以 300—500 字为宜。
% 在摘要的下方另起一行，注明本文的关键词（3—5 个）。关键词是供检索用的主题词条，应采用能覆盖论文主要内容的通用技术词条(参照相应的技术术语 标准)。按词条的外延层次排列（外延大的排在前面）。摘要与关键词应在同一页。
% modifier: 黄俊杰(huangjj27, 349373001dc@gmail.com)
% update date: 2017-04-15
%%

\cabstract{
    量化交易过程需要交易因子作为指示信号从而为交易决策提供依据。在部分高频交易场景下，交易因子大多表现为多分支机器学习模型的形式。
    高频量化交易对于低延时有严苛的要求，极低的延时是正确执行交易策略的基本条件。
    而在高频交易的关键路径中，因子模型的推理是交易延时的主要来源，因此提高因子模型推理效率成为降低延时的重要优化手段。
    然而当前广泛使用的开源模型推理框架多针对高并发场景下的推理服务进行优化，缺少针对高频交易中苛刻的低延时场景设计的优化方法。
    为此，本文提出了一种新的多分支因子模型推理框架，通过模型推理过程解耦合设计、系统友好与硬件友好的优化方法和分支推理优化算法，显著提升了多分支因子模型的推理效率。

    本文的工作具体包含推理框架的架构设计、系统友好的内存管理、硬件友好的系统配置与算子配置和分支推理优化算法四个方面。
    整体而言，我们将模型的推理过程划分为预处理和部署两个部分，其中可以通过动态配置指示框架为预处理和部署提供针对性的优化；
    其次，在预处理过程中，我们通过内存池，内存映射和内存锁定等方法预分配内存，减少运行过程中访存中断导致的延时；
    在预处理过程中，框架实现了硬件友好的算子调优，在运行过程中则可执行算子动态绑定，提高算子的执行速度；
    最后，本文引入了基于分支结构的缓存机制，通过动态配置缓存策略，有效提高推理效率。
    实验结果表明，该框架在高频交易场景下的相较开源推理框架具有优越的性能，为交易系统中的多分支因子模型推理提供了新的工具。

    %摘要应概括论文的主要信息，应具有独立性和自含性，即不阅读论文的全文，就能获得必要的信息。摘要内容一般应包括研究目的、内容、方法、成果和结论，要突出论文的创造性成果或新见解，不要与绪论相混淆。语言力求精练、准确，以300-500字为宜。
    %关键词是供检索用的主题词条，应体现论文特色，具有语义性，在论文中有明确的出处，并应尽量采用《汉语主题词表》或各专业主题词表提供的规范词。关键词与摘要应在同一页，在摘要的下方另起一行注明，一般列3-5个，按词条的外延层次排列（外延大的排在前面）。

}
% 中文关键词(每个关键词之间用“，”分开,最后一个关键词不打标点符号。)
\ckeywords{机器学习，高性能计算，低延时交易系统}

\eabstract{
    % 英文摘要及关键词内容应与中文摘要及关键词内容相同。中英文摘要及其关键词各置一页内。
    In quantitative trading, trading factors are essential signals for decision-making. 
    In today’s high-frequency trading, these factors are often multi-branch machine learning models. 
    Given the stringent low-latency requirements of high-frequency trading, minimizing latency is crucial for strategy execution. 
    Factor model inference is a key contributor to trading latency, so enhancing its efficiency is vital.
    
    However, existing open-source inference frameworks are mostly optimized for high-concurrency scenarios, lacking optimization for the low-latency needs of high-frequency trading. 
    To address this, a new multi-branch factor model inference framework is proposed. 
    It features model inference decoupling, system and hardware-friendly optimizations, and branch-specific inference algorithms, significantly boosting inference efficiency.
    
    This work encompasses four aspects: framework architecture design, memory management, hardware-friendly configurations, and branch-specific inference optimization. 
    The inference process is divided into preprocessing and deployment, with dynamic configuration for targeted optimization. 
    In preprocessing, memory allocation methods like pooling and mapping are employed to reduce latency. 
    The framework also implements operator dynamic binding and allows runtime configuration commands for faster execution. 
    Finally, a cache mechanism based on branch structures is introduced, with dynamic cache strategy configuration to enhance efficiency.
    
    Experimental results show that this framework outperforms existing open-source frameworks in high-frequency trading scenarios, offering a valuable tool for multi-branch factor model inference in trading systems.
}
% 英文文关键词(每个关键词之间用,分开, 最后一个关键词不打标点符号。)
\ekeywords{Machine Learning, High-Performance Computing, Low-Latency Trading System}
